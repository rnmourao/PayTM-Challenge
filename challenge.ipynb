{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('venv': virtualenv)",
   "display_name": "Python 3.8.5 64-bit ('venv': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "4389cfd4b26858781fc552a10b8291a92b05c799d1fc59497b8eb379bc7b14c3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, to_timestamp, col, when, sum, avg, count, split, explode, udf, collect_list, monotonically_increasing_id, row_number, size \n",
    "from pyspark.sql.functions import substring, col, to_date, datediff\n",
    "from pyspark import Row\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import ArrayType, TimestampType\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "source": [
    "# Step 1 - Setting Up the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Load the global weather data into your big data technology of choice."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = spark.read \\\n",
    "               .format(\"csv\") \\\n",
    "               .option(\"header\", \"true\") \\\n",
    "               .load(\"data/2019/*.csv\")\n",
    "weather.createOrReplaceTempView('weather')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+------+-----+-----+-----+------+\n|STN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD| GUST|   MAX|  MIN| PRCP| SNDP|FRSHTT|\n+------+-----+--------+----+----+------+------+-----+----+-----+-----+------+-----+-----+-----+------+\n|958360|99999|20190101|78.8|54.9|9999.9|9999.9|999.9| 8.8| 13.0|999.9| 96.1*| 61.9|0.00G|999.9|000000|\n|958360|99999|20190102|73.1|53.7|9999.9|9999.9|999.9| 9.5| 14.0|999.9| 89.2*|57.4*|0.00G|999.9|000000|\n|958360|99999|20190103|79.5|47.4|9999.9|9999.9|999.9| 3.2|  8.0|999.9| 96.6*| 57.2|0.00G|999.9|000000|\n|958360|99999|20190104|82.7|52.0|9999.9|9999.9|999.9|13.0| 19.0|999.9|109.8*| 60.6|0.02G|999.9|000000|\n|958360|99999|20190105|61.9|47.7|9999.9|9999.9|999.9| 8.5| 15.9|999.9| 70.5*|52.3*|0.02G|999.9|010000|\n|958360|99999|20190106|68.6|48.1|9999.9|9999.9|999.9| 9.2| 13.0|999.9| 79.9*| 52.0|0.00G|999.9|000000|\n|958360|99999|20190107|75.3|53.3|9999.9|9999.9|999.9| 5.9|  9.9|999.9| 87.8*| 55.8|0.00G|999.9|000000|\n|958360|99999|20190108|73.9|47.6|9999.9|9999.9|999.9|10.5| 15.0|999.9| 91.6*|59.0*|0.00G|999.9|000000|\n|958360|99999|20190109|65.9|42.2|9999.9|9999.9|999.9|10.1| 15.0|999.9| 77.2*|53.4*|0.00G|999.9|000000|\n|958360|99999|20190110|68.7|44.0|9999.9|9999.9|999.9| 6.8|  8.0|999.9| 79.2*| 53.1|0.00G|999.9|000000|\n|958360|99999|20190111|78.4|44.9|9999.9|9999.9|999.9| 5.9|  9.9|999.9| 92.7*| 53.8|0.00G|999.9|000000|\n|958360|99999|20190112|77.5|46.2|9999.9|9999.9|999.9|13.1| 19.0|999.9|101.3*|60.8*|0.00G|999.9|000000|\n|958360|99999|20190113|80.8|57.0|9999.9|9999.9|999.9| 7.6| 12.0|999.9| 94.3*| 60.3|0.00G|999.9|000000|\n|958360|99999|20190114|84.7|56.8|9999.9|9999.9|999.9| 4.1|  8.0|999.9|102.7*| 62.8|0.00G|999.9|000000|\n|958360|99999|20190115|87.5|43.7|9999.9|9999.9|999.9| 5.0|  8.0|999.9|106.2*| 64.0|0.00G|999.9|000000|\n|958360|99999|20190116|88.8|52.0|9999.9|9999.9|999.9| 6.9| 21.0|999.9|105.3*| 65.8|0.00G|999.9|000000|\n|958360|99999|20190117|88.3|55.2|9999.9|9999.9|999.9| 8.6| 12.0|999.9| 99.0*| 76.5|0.00G|999.9|000000|\n|958360|99999|20190118|78.0|55.6|9999.9|9999.9|999.9|10.0| 18.1|999.9| 97.7*|60.6*|0.00G|999.9|000000|\n|958360|99999|20190119|71.7|45.0|9999.9|9999.9|999.9|11.5| 15.0|999.9| 82.9*| 59.4|0.00G|999.9|000000|\n|958360|99999|20190120|77.7|56.0|9999.9|9999.9|999.9| 8.4| 14.0|999.9| 93.2*| 60.8|0.00G|999.9|000000|\n+------+-----+--------+----+----+------+------+-----+----+-----+-----+------+-----+-----+-----+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = spark.read \\\n",
    "                 .format(\"csv\") \\\n",
    "                 .option(\"header\", \"true\") \\\n",
    "                 .load(\"countrylist.csv\")\n",
    "countries.createOrReplaceTempView('countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------+--------------------+\n|COUNTRY_ABBR|        COUNTRY_FULL|\n+------------+--------------------+\n|          AA|               ARUBA|\n|          AC| ANTIGUA AND BARBUDA|\n|          AF|         AFGHANISTAN|\n|          AG|             ALGERIA|\n|          AI|    ASCENSION ISLAND|\n|          AJ|          AZERBAIJAN|\n|          AL|             ALBANIA|\n|          AM|             ARMENIA|\n|          AN|             ANDORRA|\n|          AO|              ANGOLA|\n|          AQ|      AMERICAN SAMOA|\n|          AR|           ARGENTINA|\n|          AS|           AUSTRALIA|\n|          AT|ASHMORE AND CARTI...|\n|          AU|             AUSTRIA|\n|          AV|            ANGUILLA|\n|          AX|             ANTIGUA|\n|          AY|          ANTARCTICA|\n|          AZ|              AZORES|\n|          BA|             BAHRAIN|\n+------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "countries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = spark.read \\\n",
    "                .format(\"csv\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .load(\"stationlist.csv\")\n",
    "stations.createOrReplaceTempView('stations')                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------------+\n|STN_NO|COUNTRY_ABBR|\n+------+------------+\n|012240|          NO|\n|020690|          SW|\n|020870|          SW|\n|021190|          SW|\n|032690|          UK|\n|033450|          UK|\n|039290|          UK|\n|039790|          EI|\n|040480|          IC|\n|041300|          IC|\n|060100|          FO|\n|061443|          DA|\n|063401|          NL|\n|071910|          FR|\n|092640|          GM|\n|123766|          PL|\n|125990|          PL|\n|129700|          HU|\n|132240|          HR|\n|156500|          BU|\n+------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "stations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('STN_NO', 'string'), ('COUNTRY_ABBR', 'string')]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "stations.dtypes"
   ]
  },
  {
   "source": [
    "## 2. Join the stationlist.csv with the countrylist.csv to get the full country name for each station number.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_n_countries = spark.sql(\"\"\"\n",
    "select a.STN_NO\n",
    "     , b.COUNTRY_ABBR\n",
    "     , b.COUNTRY_FULL\n",
    "from stations a inner join countries b on a.COUNTRY_ABBR = b.COUNTRY_ABBR\n",
    "\"\"\")\n",
    "stations_n_countries.createOrReplaceTempView('stations_n_countries') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------------+--------------+\n|STN_NO|COUNTRY_ABBR|  COUNTRY_FULL|\n+------+------------+--------------+\n|012240|          NO|        NORWAY|\n|020690|          SW|        SWEDEN|\n|020870|          SW|        SWEDEN|\n|021190|          SW|        SWEDEN|\n|032690|          UK|UNITED KINGDOM|\n|033450|          UK|UNITED KINGDOM|\n|039290|          UK|UNITED KINGDOM|\n|039790|          EI|       IRELAND|\n|040480|          IC|       ICELAND|\n|041300|          IC|       ICELAND|\n|060100|          FO| FAROE ISLANDS|\n|061443|          DA|       DENMARK|\n|063401|          NL|   NETHERLANDS|\n|071910|          FR|        FRANCE|\n|092640|          GM|       GERMANY|\n|123766|          PL|        POLAND|\n|125990|          PL|        POLAND|\n|129700|          HU|       HUNGARY|\n|132240|          HR|       CROATIA|\n|156500|          BU|      BULGARIA|\n+------+------------+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "stations_n_countries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "stations.count() - stations_n_countries.count()"
   ]
  },
  {
   "source": [
    "## 3. Join the global weather data with the full country names by station number."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "select a.*\n",
    "     , b.COUNTRY_ABBR\n",
    "     , b.COUNTRY_FULL\n",
    "from weather a inner join stations_n_countries b on a.`STN---` = b.STN_NO\n",
    "\"\"\")\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+------------+\n|STN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD| GUST|  MAX|  MIN| PRCP| SNDP|FRSHTT|COUNTRY_ABBR|COUNTRY_FULL|\n+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+------------+\n|010875|99999|20190101|41.1|30.1|9999.9|9999.9|  5.9|46.7| 59.1| 74.0|44.6*|37.4*|99.99|999.9|011010|          NO|      NORWAY|\n|010875|99999|20190102|40.5|29.0|9999.9|9999.9|  6.2|20.5| 32.1| 44.1|41.0*|37.4*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190103|43.0|36.6|9999.9|9999.9|  6.1|13.5| 21.0|999.9|44.6*|41.0*|0.00I|999.9|000000|          NO|      NORWAY|\n|010875|99999|20190104|46.7|44.4|9999.9|9999.9|  5.8|27.4| 33.0| 40.0|48.2*|42.8*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190105|46.5|44.1|9999.9|9999.9|  6.1|18.3| 25.1|999.9|48.2*|44.6*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190106|45.5|39.4|9999.9|9999.9|  5.7|16.4| 24.1|999.9|46.4*|42.8*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190107|45.1|40.5|9999.9|9999.9|  5.4|28.5| 47.0| 56.9|48.2*|42.8*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190108|42.3|33.6|9999.9|9999.9|  6.1|35.7| 44.1| 55.9|46.4*|37.4*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190109|40.7|31.0|9999.9|9999.9|  6.2|16.8| 25.1| 35.0|42.8*|39.2*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190110|47.2|45.3|9999.9|9999.9|  3.5|25.7| 29.9|999.9|48.2*|41.0*|99.99|999.9|110000|          NO|      NORWAY|\n|010875|99999|20190111|44.5|39.6|9999.9|9999.9|  5.8|19.5| 29.9|999.9|46.4*|42.8*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190112|45.2|41.6|9999.9|9999.9|  5.9|27.3| 35.0| 44.1|46.4*|42.8*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190113|41.5|34.6|9999.9|9999.9|  5.7|35.3| 48.0| 60.0|46.4*|32.0*|99.99|999.9|111000|          NO|      NORWAY|\n|010875|99999|20190114|34.2|28.0|9999.9|9999.9|  5.5|25.8| 46.0| 60.0|37.4*|30.2*|99.99|999.9|011000|          NO|      NORWAY|\n|010875|99999|20190115|43.3|36.8|9999.9|9999.9|  5.8|25.8| 40.0| 46.0|46.4*|35.6*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190116|41.4|36.3|9999.9|9999.9|  6.1|27.3| 45.1| 48.0|46.4*|33.8*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190117|36.5|28.9|9999.9|9999.9|  5.8|23.5| 42.0| 53.0|39.2*|33.8*|99.99|999.9|011000|          NO|      NORWAY|\n|010875|99999|20190118|39.4|26.7|9999.9|9999.9|  6.1|12.1| 18.1| 21.0|41.0*|32.0*|99.99|999.9|010000|          NO|      NORWAY|\n|010875|99999|20190119|40.9|33.8|9999.9|9999.9|  6.2| 9.9| 15.0|999.9|42.8*|39.2*|0.00I|999.9|000000|          NO|      NORWAY|\n|010875|99999|20190120|42.3|36.5|9999.9|9999.9|  6.2|20.8| 34.0| 36.9|42.8*|39.2*|99.99|999.9|010000|          NO|      NORWAY|\n+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15249"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "weather.count() - df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4158416"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "weather.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('NTEMP', df.TEMP.cast('float')) \\\n",
    "       .withColumn('NWDSP', df.WDSP.cast('float')) \\\n",
    "       .withColumn('tornado', substring(col('FRSHTT'), -1, 1).cast('int')) \\\n",
    "       .withColumn('dt', to_date('YEARMODA', 'yyyyMMdd'))\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('STN---', 'string'),\n",
       " ('WBAN', 'string'),\n",
       " ('YEARMODA', 'string'),\n",
       " ('TEMP', 'string'),\n",
       " ('DEWP', 'string'),\n",
       " ('SLP', 'string'),\n",
       " ('STP', 'string'),\n",
       " ('VISIB', 'string'),\n",
       " ('WDSP', 'string'),\n",
       " ('MXSPD', 'string'),\n",
       " ('GUST', 'string'),\n",
       " ('MAX', 'string'),\n",
       " ('MIN', 'string'),\n",
       " ('PRCP', 'string'),\n",
       " ('SNDP', 'string'),\n",
       " ('FRSHTT', 'string'),\n",
       " ('COUNTRY_ABBR', 'string'),\n",
       " ('COUNTRY_FULL', 'string'),\n",
       " ('NTEMP', 'float'),\n",
       " ('NWDSP', 'float'),\n",
       " ('tornado', 'int'),\n",
       " ('dt', 'date')]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "source": [
    "# Step 2 - Questions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Which country had the hottest average mean temperature over the year?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+----+--------+----+----+---+---+-----+----+-----+----+---+---+----+----+------+------------+------------+-----+-----+-------+---+\n|STN---|WBAN|YEARMODA|TEMP|DEWP|SLP|STP|VISIB|WDSP|MXSPD|GUST|MAX|MIN|PRCP|SNDP|FRSHTT|COUNTRY_ABBR|COUNTRY_FULL|NTEMP|NWDSP|tornado| dt|\n+------+----+--------+----+----+---+---+-----+----+-----+----+---+---+----+----+------+------------+------------+-----+-----+-------+---+\n+------+----+--------+----+----+---+---+-----+----+-----+----+---+---+----+----+------+------------+------------+-----+-----+-------+---+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select *\n",
    "from df\n",
    "where NTEMP >= 9999.9\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+-----------------+\n| country|         avg_temp|\n+--------+-----------------+\n|DJIBOUTI|90.06114474836602|\n+--------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select country\n",
    "     , avg_temp\n",
    "from (\n",
    "    select COUNTRY_FULL as country\n",
    "         , avg(NTEMP) as avg_temp\n",
    "    from df\n",
    "    where NTEMP < 9999.9\n",
    "    group by COUNTRY_FULL\n",
    "    )\n",
    "order by avg_temp desc\n",
    "limit 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "source": [
    "##  2. Which country had the most consecutive days of tornadoes/funnel cloud formations?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tornadoes = spark.sql(\"\"\"\n",
    "select dt\n",
    "     , COUNTRY_FULL as country\n",
    "     , max(tornado) as tornado\n",
    "from df\n",
    "where tornado = 1\n",
    "group by dt, COUNTRY_FULL\n",
    "order by COUNTRY_FULL, dt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+-----------+-------+\n|        dt|    country|tornado|\n+----------+-----------+-------+\n|2019-07-04|    ALGERIA|      1|\n|2019-02-06|     ANGOLA|      1|\n|2019-04-05|     ANGOLA|      1|\n|2019-06-06|   ANGUILLA|      1|\n|2019-05-10|  ARGENTINA|      1|\n|2019-09-23|      ARUBA|      1|\n|2019-01-20|    AUSTRIA|      1|\n|2019-06-16|    AUSTRIA|      1|\n|2019-06-19|    AUSTRIA|      1|\n|2019-10-14|    AUSTRIA|      1|\n|2019-10-19|    AUSTRIA|      1|\n|2019-02-25|BAHAMAS THE|      1|\n|2019-03-27|BAHAMAS THE|      1|\n|2019-04-02|BAHAMAS THE|      1|\n|2019-04-15|BAHAMAS THE|      1|\n|2019-04-29|BAHAMAS THE|      1|\n|2019-06-02|BAHAMAS THE|      1|\n|2019-06-15|BAHAMAS THE|      1|\n|2019-07-04|BAHAMAS THE|      1|\n|2019-08-06|BAHAMAS THE|      1|\n+----------+-----------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "tornadoes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_event = tornadoes.withColumn(\"last_event\", lag('dt').over(Window.partitionBy('country').orderBy('dt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------------+-------+----------+\n|        dt|       country|tornado|last_event|\n+----------+--------------+-------+----------+\n|2019-08-22|    BANGLADESH|      1|      null|\n|2019-01-17|         JAPAN|      1|      null|\n|2019-01-24|         JAPAN|      1|2019-01-17|\n|2019-03-02|         JAPAN|      1|2019-01-24|\n|2019-04-02|         JAPAN|      1|2019-03-02|\n|2019-06-10|         JAPAN|      1|2019-04-02|\n|2019-06-11|         JAPAN|      1|2019-06-10|\n|2019-08-10|         JAPAN|      1|2019-06-11|\n|2019-08-30|         JAPAN|      1|2019-08-10|\n|2019-12-03|         JAPAN|      1|2019-08-30|\n|2019-12-04|         JAPAN|      1|2019-12-03|\n|2019-12-14|         JAPAN|      1|2019-12-04|\n|2019-06-12|        JERSEY|      1|      null|\n|2019-11-09|      MALDIVES|      1|      null|\n|2019-05-17|      TANZANIA|      1|      null|\n|2019-01-19|         MALTA|      1|      null|\n|2019-05-14|         MALTA|      1|2019-01-19|\n|2019-06-12|UNITED KINGDOM|      1|      null|\n|2019-06-20|UNITED KINGDOM|      1|2019-06-12|\n|2019-09-07|UNITED KINGDOM|      1|2019-06-20|\n+----------+--------------+-------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "last_event.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = last_event.withColumn('lag', datediff(col('dt'), col('last_event')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------------+-------+----------+----+\n|        dt|       country|tornado|last_event| lag|\n+----------+--------------+-------+----------+----+\n|2019-08-22|    BANGLADESH|      1|      null|null|\n|2019-01-17|         JAPAN|      1|      null|null|\n|2019-01-24|         JAPAN|      1|2019-01-17|   7|\n|2019-03-02|         JAPAN|      1|2019-01-24|  37|\n|2019-04-02|         JAPAN|      1|2019-03-02|  31|\n|2019-06-10|         JAPAN|      1|2019-04-02|  69|\n|2019-06-11|         JAPAN|      1|2019-06-10|   1|\n|2019-08-10|         JAPAN|      1|2019-06-11|  60|\n|2019-08-30|         JAPAN|      1|2019-08-10|  20|\n|2019-12-03|         JAPAN|      1|2019-08-30|  95|\n|2019-12-04|         JAPAN|      1|2019-12-03|   1|\n|2019-12-14|         JAPAN|      1|2019-12-04|  10|\n|2019-06-12|        JERSEY|      1|      null|null|\n|2019-11-09|      MALDIVES|      1|      null|null|\n|2019-05-17|      TANZANIA|      1|      null|null|\n|2019-01-19|         MALTA|      1|      null|null|\n|2019-05-14|         MALTA|      1|2019-01-19| 115|\n|2019-06-12|UNITED KINGDOM|      1|      null|null|\n|2019-06-20|UNITED KINGDOM|      1|2019-06-12|   8|\n|2019-09-07|UNITED KINGDOM|      1|2019-06-20|  79|\n+----------+--------------+-------+----------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "lags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_period = lags.withColumn('is_new_period', when( col('lag') > 1, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------------+-------+----------+----+-------------+\n|        dt|       country|tornado|last_event| lag|is_new_period|\n+----------+--------------+-------+----------+----+-------------+\n|2019-08-22|    BANGLADESH|      1|      null|null|            0|\n|2019-01-17|         JAPAN|      1|      null|null|            0|\n|2019-01-24|         JAPAN|      1|2019-01-17|   7|            1|\n|2019-03-02|         JAPAN|      1|2019-01-24|  37|            1|\n|2019-04-02|         JAPAN|      1|2019-03-02|  31|            1|\n|2019-06-10|         JAPAN|      1|2019-04-02|  69|            1|\n|2019-06-11|         JAPAN|      1|2019-06-10|   1|            0|\n|2019-08-10|         JAPAN|      1|2019-06-11|  60|            1|\n|2019-08-30|         JAPAN|      1|2019-08-10|  20|            1|\n|2019-12-03|         JAPAN|      1|2019-08-30|  95|            1|\n|2019-12-04|         JAPAN|      1|2019-12-03|   1|            0|\n|2019-12-14|         JAPAN|      1|2019-12-04|  10|            1|\n|2019-06-12|        JERSEY|      1|      null|null|            0|\n|2019-11-09|      MALDIVES|      1|      null|null|            0|\n|2019-05-17|      TANZANIA|      1|      null|null|            0|\n|2019-01-19|         MALTA|      1|      null|null|            0|\n|2019-05-14|         MALTA|      1|2019-01-19| 115|            1|\n|2019-06-12|UNITED KINGDOM|      1|      null|null|            0|\n|2019-06-20|UNITED KINGDOM|      1|2019-06-12|   8|            1|\n|2019-09-07|UNITED KINGDOM|      1|2019-06-20|  79|            1|\n+----------+--------------+-------+----------+----+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "new_period.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_period_id = new_period.withColumn(\"country_period_id\", sum('is_new_period').over(Window.partitionBy('country').orderBy('dt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------------+-------+----------+----+-------------+-----------------+\n|        dt|       country|tornado|last_event| lag|is_new_period|country_period_id|\n+----------+--------------+-------+----------+----+-------------+-----------------+\n|2019-08-22|    BANGLADESH|      1|      null|null|            0|                0|\n|2019-01-17|         JAPAN|      1|      null|null|            0|                0|\n|2019-01-24|         JAPAN|      1|2019-01-17|   7|            1|                1|\n|2019-03-02|         JAPAN|      1|2019-01-24|  37|            1|                2|\n|2019-04-02|         JAPAN|      1|2019-03-02|  31|            1|                3|\n|2019-06-10|         JAPAN|      1|2019-04-02|  69|            1|                4|\n|2019-06-11|         JAPAN|      1|2019-06-10|   1|            0|                4|\n|2019-08-10|         JAPAN|      1|2019-06-11|  60|            1|                5|\n|2019-08-30|         JAPAN|      1|2019-08-10|  20|            1|                6|\n|2019-12-03|         JAPAN|      1|2019-08-30|  95|            1|                7|\n|2019-12-04|         JAPAN|      1|2019-12-03|   1|            0|                7|\n|2019-12-14|         JAPAN|      1|2019-12-04|  10|            1|                8|\n|2019-06-12|        JERSEY|      1|      null|null|            0|                0|\n|2019-11-09|      MALDIVES|      1|      null|null|            0|                0|\n|2019-05-17|      TANZANIA|      1|      null|null|            0|                0|\n|2019-01-19|         MALTA|      1|      null|null|            0|                0|\n|2019-05-14|         MALTA|      1|2019-01-19| 115|            1|                1|\n|2019-06-12|UNITED KINGDOM|      1|      null|null|            0|                0|\n|2019-06-20|UNITED KINGDOM|      1|2019-06-12|   8|            1|                1|\n|2019-09-07|UNITED KINGDOM|      1|2019-06-20|  79|            1|                2|\n+----------+--------------+-------+----------+----+-------------+-----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "country_period_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_period_id.createOrReplaceTempView('tornado_period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+-----------------+---+\n|country|country_period_id|qty|\n+-------+-----------------+---+\n|  JAPAN|                4|  1|\n+-------+-----------------+---+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select *\n",
    "from (\n",
    "    select country\n",
    "         , country_period_id\n",
    "         , count(1) as qty\n",
    "    from tornado_period\n",
    "    where lag = 1\n",
    "    group by country, country_period_id\n",
    ")\n",
    "order by qty desc\n",
    "limit 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "source": [
    "## 3. Which country had the second highest average mean wind speed over the year?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+--------+-----+-----+------+------+-----+-----+-----+-----+------+------+-----+-----+------+------------+------------+-----+-----+\n|STN---| WBAN|YEARMODA| TEMP| DEWP|   SLP|   STP|VISIB| WDSP|MXSPD| GUST|   MAX|   MIN| PRCP| SNDP|FRSHTT|COUNTRY_ABBR|COUNTRY_FULL|NTEMP|NWDSP|\n+------+-----+--------+-----+-----+------+------+-----+-----+-----+-----+------+------+-----+-----+------+------------+------------+-----+-----+\n|232050|99999|20191223| -0.2| -3.6|1015.5|1014.1|  5.7|999.9|999.9|999.9|  16.0| -7.6*|0.02F|999.9|101000|          RS|      RUSSIA| -0.2|999.9|\n|232050|99999|20191224|-17.3|-22.1|1019.0|1017.4|  4.7|999.9|999.9|999.9| -9.6*|-22.7*|0.01F| 19.7|100000|          RS|      RUSSIA|-17.3|999.9|\n|232050|99999|20191225|-21.8|-27.0|1023.1|1021.6| 12.4|999.9|999.9|999.9| -17.9| -25.6|0.00F| 19.7|000000|          RS|      RUSSIA|-21.8|999.9|\n|255610|99999|20190113|-31.5|-38.2|1021.2|1020.0| 31.1|999.9|999.9|999.9|-28.5*| -35.5|0.00I|  7.9|000000|          RS|      RUSSIA|-31.5|999.9|\n|255610|99999|20190119|-10.9|-17.4|1021.1|1020.0| 12.4|999.9|999.9|999.9| -8.5*|-14.4*|99.99|999.9|001000|          RS|      RUSSIA|-10.9|999.9|\n|255610|99999|20190121| -1.5| -7.6|1025.6|1024.5| 10.9|999.9|999.9|999.9|  0.7*| -4.5*|99.99|  7.9|001000|          RS|      RUSSIA| -1.5|999.9|\n|255610|99999|20190123|-25.9|-32.4|1015.6|1014.5| 31.1|999.9|999.9|999.9|-19.1*| -31.7|0.00I|  7.9|000000|          RS|      RUSSIA|-25.9|999.9|\n|255610|99999|20190130|-24.4|-31.0|1023.1|1022.0| 31.1|999.9|999.9|999.9|-20.7*| -28.5|0.00I|  7.9|000000|          RS|      RUSSIA|-24.4|999.9|\n|255610|99999|20190222|  9.4|  4.0|1002.3|1001.3|  8.1|999.9|999.9|999.9| 14.9*|  1.2*|0.02E|999.9|001000|          RS|      RUSSIA|  9.4|999.9|\n|255610|99999|20190309| -9.6|-16.1|1001.8|1000.8| 21.7|999.9|999.9|999.9|   1.0| -21.3|0.00E| 14.6|000000|          RS|      RUSSIA| -9.6|999.9|\n|296450|99999|20190101| -0.3| -3.5|1037.7|1017.4|  1.9|999.9|999.9|999.9|   9.0|-10.7*|0.02F| 18.9|001000|          RS|      RUSSIA| -0.3|999.9|\n|296450|99999|20190103|-13.3|-18.3|1042.0|1021.0|  3.0|999.9|999.9|999.9|  -4.0|-20.7*|0.00F| 18.9|001000|          RS|      RUSSIA|-13.3|999.9|\n|296450|99999|20190104|-17.9|-23.6|1035.6|1014.5|  0.9|999.9|999.9|999.9|  -9.2|-22.4*|0.01F| 18.9|001000|          RS|      RUSSIA|-17.9|999.9|\n|296450|99999|20190202|-34.7|-43.1|1042.6|1020.5|  4.2|999.9|999.9|999.9| -24.9| -45.0|0.00F| 23.2|000000|          RS|      RUSSIA|-34.7|999.9|\n|296450|99999|20190207|-24.5|-32.9|1048.7|1027.0|  2.6|999.9|999.9|999.9| -11.2| -33.2|0.00F| 22.8|000000|          RS|      RUSSIA|-24.5|999.9|\n|296450|99999|20190208|-24.6|-32.9|1050.5|1028.8|  2.3|999.9|999.9|999.9|  -4.9| -36.2|0.00F| 22.8|000000|          RS|      RUSSIA|-24.6|999.9|\n|296450|99999|20190209|-25.3|-33.7|1043.0|1021.4|  1.2|999.9|999.9|999.9|  -9.9| -38.2|0.00F| 22.4|000000|          RS|      RUSSIA|-25.3|999.9|\n|296450|99999|20190210|-18.7|-27.4|1030.3|1009.2|  0.8|999.9|999.9|999.9|  -4.5| -34.2|0.00F| 22.4|000000|          RS|      RUSSIA|-18.7|999.9|\n|296450|99999|20190211|-10.1|-18.1|1032.2|1011.5|  1.8|999.9|999.9|999.9|   4.3| -26.5|0.00F| 22.4|000000|          RS|      RUSSIA|-10.1|999.9|\n|296450|99999|20190212| -6.4|-12.3|1035.1|1014.6|  6.7|999.9|999.9|999.9|  13.3| -17.5|0.00F| 22.8|001000|          RS|      RUSSIA| -6.4|999.9|\n+------+-----+--------+-----+-----+------+------+-----+-----+-----+-----+------+------+-----+-----+------+------------+------------+-----+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select *\n",
    "from df\n",
    "where NWDSP >= 999.9\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+-----------------+\n|country|   avg_wind_speed|\n+-------+-----------------+\n| ZAMBIA|5.920833328117927|\n+-------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select country\n",
    "     , avg_wind_speed\n",
    "from (\n",
    "        select *\n",
    "            , row_number() over (order by country desc) as rn\n",
    "        from (\n",
    "                select COUNTRY_FULL as country\n",
    "                    , avg(NWDSP) as avg_wind_speed\n",
    "                from df\n",
    "                where NWDSP < 999.9\n",
    "                group by COUNTRY_FULL\n",
    "        )\n",
    ")\n",
    "where rn = 2\n",
    "\"\"\").show()"
   ]
  }
 ]
}